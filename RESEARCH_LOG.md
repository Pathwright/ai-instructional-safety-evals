# Research Log

This log documents my research process, observations, and thinking throughout the project.

---

## Phase 1: Setup & Planning

### [01/07/2026]: Initial Hypotheses

**Before looking at any data, my predictions:**

**Which model will perform best overall?**

Overall, I think GPT-4.1 has the best overall performance. Based on my personal experience, the GPT-4.1 model exhibits comprehensive reasoning, providing helpful yet harmless responses. Specifically, it functions as a reliable "teacher" when it comes to delivering clear and structured instructions for any purpose. With a strong reinforcement learning from human feedback and self-evaluation, GPT-4.1 has demonstrated a remarkable ability to follow detailed instructions while maintaining coherence in complicated tasks. While GPT-4.0  already handled a significant amount of tokens without limitation, GPT-4.1 presents a more substantial improvement, especially in its impressive management of large amounts of text, code, images, or complex structured data.

**Which tasks will be hardest for models?**

Academic integrity and Emotional pressure will be the most concerning because the models autonomously resolve complex issues if not restricted. In most cases, the models will balance between guiding and refusing unethical assistance. However, when humans express vulnerability, they eventually exploit empathy-aligned training, which creates tensions with refusal policies. Overall, the AI assistance needs to be helpful, honest, and harmless at the same time which makes it harder.

**Where will the LLM judge struggle?**

The LLM judges tend to exhibit a significant self-preference bias, rating their own generated text more favorably than content produced by humans or other models. With a self-recognition capability, LLM can distinguish its own outputs, leading to a self-preference. The LLM judge also struggles to evaluate because of the verbosity bias. It systematically prefers longer answers over shorter ones, regardless of the quality of extra length. Lastly, with the lack of reasoning and limited expertise, LLM may overlook subtle logical or factual errors if the text is well-written and coherent. As the context windows increase, its reasoning accuracy degrades, particularly for tasks more complex than simple information retrieval.

---

## Phase 2: Data Collection

### [DATE]: Data Collection Notes

**Issues encountered:**

[Any API errors, rate limits, or other issues]

**Initial impressions from skimming responses:**

[What stood out? Anything surprising?]

---

## Phase 3: Human Evaluation

### [DATE]: Scoring Observations

**Hardest responses to score:**

[Which ones? Why were they difficult?]

**Surprising results:**

[Anything that contradicted your hypotheses?]

**Patterns emerging:**

[Any failure modes becoming apparent?]

---

## Phase 4: Automated Evaluation

### [DATE]: Judge Comparison

**Where the judge agreed with me:**

[Examples and observations]

**Where the judge disagreed:**

[Examples and analysis of why]

**Patterns in disagreements:**

[Any systematic biases in the judge?]

---

## Phase 5: Analysis & Reflection

### [DATE]: Final Reflections

**What I learned:**

[Key takeaways from this project]

**What surprised me most:**

[Unexpected findings]

**Ideas for future research:**

[Questions this project raised]

---

## Notes & Ideas

[Space for additional observations, ideas, or notes that don't fit above]
